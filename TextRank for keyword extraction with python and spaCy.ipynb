{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I am gonna implement TextRank algorithm and calculate keyword score of each word. spaCy is used to get POS tag of words. \n",
    "\n",
    "In TextRank each word is considered as a node. w1,w2,...wn are n words. I set the window size as k. That is [w1, w2, …, w_k], [w2, w3, …, w_{k+1}], [w3, w4, …, w_{k+2}]. Any two-word pairs in a window are considered have an undirected edge. We take [time, Wandering, Earth, feels, throwback, eras, filmmaking] as the example, and set the window size k=4, so we get 4 windows, [time, Wandering, Earth, feels], [Wandering, Earth, feels, throwback], [Earth, feels, throwback, eras], [feels, throwback, eras, filmmaking].For window [time, Wandering, Earth, feels], any two words pair has an undirected edge. So we get (time, Wandering), (time, Earth), (time, feels), (Wandering, Earth), (Wandering, feels), (Earth, feels).\n",
    "\n",
    "Since most of the words like preposition in a sentence have little semantic value. In this project I only consider only consider the words with NOUN, PROPN, VERB POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keywords():\n",
    "    def __init__(self):\n",
    "        self.d = 0.85 #damping coefficient, usually is .85\n",
    "        self.diff = 1e-5 #convergence threshold\n",
    "        self.steps = 20 #iteration steps\n",
    "        self.node_weight = None # keywords and its weight\n",
    "    '''define stop words'''\n",
    "    def stopwords(self,stopwords):\n",
    "        for token in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[token]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "    '''get words with some POS tags'''\n",
    "    def get_words(self, doc, pos, lower):\n",
    "        sent = []\n",
    "        for sentence in doc.sents:\n",
    "            word = []\n",
    "            for token in sentence:\n",
    "                if token.pos_ in pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        word.append(token.text.lower())\n",
    "                    else:\n",
    "                        word.append(token.text)\n",
    "            sent.append(word)\n",
    "        return sent\n",
    "\n",
    "    '''built word:apperance_order dictionary'''\n",
    "    def get_vocab(self, doc):\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sent in doc:\n",
    "            for word in sent:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1               \n",
    "        return vocab\n",
    "\n",
    "    '''build token pair with certain lenght window'''\n",
    "    def get_pairs(self, window_len, doc):\n",
    "        token_pair = []\n",
    "        for sent in doc:\n",
    "            for i,word in enumerate(sent):\n",
    "                for j in range(i+1, i+window_len):\n",
    "                    if j >= len(sent):\n",
    "                        break\n",
    "                    pair = (word, sent[j])\n",
    "                    if pair not in token_pair:\n",
    "                        token_pair.append(pair)\n",
    "        return token_pair\n",
    "\n",
    "    def symmetrize(self, m):\n",
    "        return m+m.T-np.diag(m.diagonal())\n",
    "\n",
    "    '''contruct token directed matrix'''\n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        size = len(vocab)\n",
    "        m = np.zeros((size,size), dtype = 'float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            m[i][j] = 1\n",
    "\n",
    "        m = self.symmetrize(m)\n",
    "        \n",
    "        '''normalize matrix'''\n",
    "        s = np.sum(m, axis = 0)\n",
    "        normalized = np.divide(m, s, where=s!= 0 ) #ignore 0 element in norm\n",
    "\n",
    "        return normalized\n",
    "\n",
    "    '''main function to calculate weight for each word'''\n",
    "    def analyze(self, doc, pos=['NOUN', 'PROPN', 'VERB'], window_len = 3, lower = False, stopwords = list()):\n",
    "\n",
    "        doc = nlp(doc)\n",
    "        self.stopwords(stopwords)\n",
    "        sents = self.get_words(doc, pos, lower)\n",
    "        vocab = self.get_vocab(sents)\n",
    "        token_pairs = self.get_pairs(window_len, sents)\n",
    "        m = self.get_matrix(vocab, token_pairs)\n",
    "\n",
    "        w = np.array([1]*len(vocab))\n",
    "\n",
    "        pre_value = 0\n",
    "        for i in range(self.steps):\n",
    "            w = (1-self.d) + self.d * np.dot(m, w)\n",
    "            if abs(pre_value-sum(w)) < self.diff:\n",
    "                break\n",
    "            else:\n",
    "                pre_value = sum(w)\n",
    "\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = w[index]\n",
    "\n",
    "        self.node_weight = node_weight\n",
    "\n",
    "\n",
    "    '''print top 10 keywords'''\n",
    "    def get_keywords(self, num = 10):\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key = lambda t:t[1], reverse = True))\n",
    "        for i, (key,value) in enumerate(node_weight.items()):\n",
    "            print(key+':'+str(value))\n",
    "            if i > num:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "The Wandering Earth, described as China’s first big-budget science fiction thriller, quietly made it onto screens at AMC theaters in North America this weekend, and it shows a new side of Chinese filmmaking — one focused toward futuristic spectacles rather than China’s traditionally grand, massive historical epics. At the same time, The Wandering Earth feels like a throwback to a few familiar eras of American filmmaking. While the film’s cast, setting, and tone are all Chinese, longtime science fiction fans are going to see a lot on the screen that reminds them of other movies, for better or worse.\n",
    "'''\n",
    "\n",
    "test1 = keywords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.analyze(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get top 10 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China:1.500404974489796\n",
      "science:1.4267889030612242\n",
      "Earth:1.3999011479591834\n",
      "fiction:1.3888424744897958\n",
      "filmmaking:1.3209424603174602\n",
      "screen:1.1285119047619045\n",
      "setting:1.0898065476190473\n",
      "lot:1.0729836309523808\n",
      "tone:1.0565582482993197\n",
      "feels:1.0121850198412696\n",
      "going:1.0118356717687074\n",
      "focused:1.0026442035147392\n"
     ]
    }
   ],
   "source": [
    "test1.get_keywords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "referece:Xu Liang https://github.com/BrambleXu/news-graph?source=post_page-----c0bae21bcec0----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
